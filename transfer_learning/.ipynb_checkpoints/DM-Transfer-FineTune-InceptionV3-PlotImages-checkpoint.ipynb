{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "# Generacion del grafico de metricas de Perdidas y Accuracy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#ML\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.applications import *\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as k\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "#seed = 9\n",
    "#np.random.seed(seed=seed)\n",
    "#tf.set_random_seed(seed=seed)\n",
    "\n",
    "# parameters dependent on your dataset: modified to your example\n",
    "nb_train_samples = 690  # Total number of train samples. NOT including augmented images\n",
    "nb_validation_samples = 346  # Total number of train samples. NOT including augmented images.\n",
    "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
    "\n",
    "# hyper parameters for model\n",
    "based_model_last_block_layer_number = 172  # value is based on based model selected.\n",
    "batch_size = 64#8  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 10#100  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-4  # sgd learning rate\n",
    "momentum = .9  # sgd momentum to avoid local minimum\n",
    "\n",
    "#Dataset\n",
    "#data_dir = './data/DDSM Images'\n",
    "data_dir = './data/DM images'\n",
    "train_dir = data_dir + '/train'  # change to your train path. Inside, each class should have it's own folder\n",
    "validation_dir = data_dir + '/validation'  # validation path. Inside, each class should have it's own folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grupoavatar/.local/lib/python3.5/site-packages/ipykernel_launcher.py:63: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/grupoavatar/.local/lib/python3.5/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=346, steps_per_epoch=10, validation_data=<keras.pre..., epochs=2.0, callbacks=[<keras.ca...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.5732 - acc: 0.6545Epoch 00001: val_acc improved from -inf to 0.75000, saving model to model/top_model_weights.h5\n",
      "10/10 [==============================] - 135s 13s/step - loss: 1.4442 - acc: 0.6623 - val_loss: 0.7053 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6823 - acc: 0.6944Epoch 00002: val_acc did not improve\n",
      "10/10 [==============================] - 127s 13s/step - loss: 0.7110 - acc: 0.7000 - val_loss: 0.6316 - val_acc: 0.7500\n",
      "\n",
      "Starting to Fine Tune Model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grupoavatar/.local/lib/python3.5/site-packages/keras/callbacks.py:375: RuntimeWarning: ModelCheckpoint mode mode is unknown, fallback to auto mode.\n",
      "  RuntimeWarning)\n",
      "/home/grupoavatar/.local/lib/python3.5/site-packages/ipykernel_launcher.py:100: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/grupoavatar/.local/lib/python3.5/site-packages/ipykernel_launcher.py:100: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=346, steps_per_epoch=10, validation_data=<keras.pre..., epochs=10, callbacks=[<keras.ca...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6265 - acc: 0.7604Epoch 00001: val_loss improved from inf to 0.68484, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.6200 - acc: 0.7611 - val_loss: 0.6848 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6530 - acc: 0.7361Epoch 00002: val_loss improved from 0.68484 to 0.64869, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.6292 - acc: 0.7389 - val_loss: 0.6487 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5914 - acc: 0.7326Epoch 00003: val_loss improved from 0.64869 to 0.61261, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.5886 - acc: 0.7460 - val_loss: 0.6126 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5978 - acc: 0.6979Epoch 00004: val_loss improved from 0.61261 to 0.59455, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 130s 13s/step - loss: 0.5809 - acc: 0.7070 - val_loss: 0.5945 - val_acc: 0.7321\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5946 - acc: 0.7153Epoch 00005: val_loss improved from 0.59455 to 0.58720, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.5894 - acc: 0.7207 - val_loss: 0.5872 - val_acc: 0.7321\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5713 - acc: 0.7274Epoch 00006: val_loss improved from 0.58720 to 0.58420, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.5814 - acc: 0.7217 - val_loss: 0.5842 - val_acc: 0.7321\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6075 - acc: 0.7222Epoch 00007: val_loss improved from 0.58420 to 0.58370, saving model to model/model_weights.h5\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.5830 - acc: 0.7375 - val_loss: 0.5837 - val_acc: 0.7321\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5089 - acc: 0.7465Epoch 00008: val_loss did not improve\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.5108 - acc: 0.7460 - val_loss: 0.5900 - val_acc: 0.7321\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5414 - acc: 0.7604Epoch 00009: val_loss did not improve\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.5500 - acc: 0.7545 - val_loss: 0.5938 - val_acc: 0.7321\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5381 - acc: 0.7622Epoch 00010: val_loss did not improve\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.5411 - acc: 0.7588 - val_loss: 0.5978 - val_acc: 0.7321\n"
     ]
    }
   ],
   "source": [
    "def train(train_data_dir, validation_data_dir):\n",
    "    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)  # select from keras pre-built models library\n",
    "\n",
    "    # Top Model Block\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # softmax if multi-class classifiers\n",
    "    #predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "\n",
    "    # add your top layer block to your base model\n",
    "    model = Model(base_model.input, predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolution layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
    "    # To save augmentations un-comment save lines and add to your flow parameters.\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       #rotation_range=10,\n",
    "                                       shear_range=.1,\n",
    "                                       zoom_range=.1,\n",
    "                                       cval=.1,\n",
    "                                       horizontal_flip=True)\n",
    "                                       #vertical_flip=True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary')\n",
    "                                                        #save_to_dir=data_dir + '/preview',\n",
    "                                                        #save_prefix='aug')#,\n",
    "                                                        #save_format='jpeg')\n",
    "    # use the above 3 commented lines if you want to save and look at how the data augmentations look like\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                            target_size=(img_height, img_width),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='binary')\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])\n",
    "    #  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
    "    top_weights_path = 'model/top_model_weights.h5'\n",
    "    checkpoint = ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Train Simple CNN\n",
    "    history_tl = model.fit_generator(train_generator,\n",
    "                        samples_per_epoch=nb_train_samples,\n",
    "                        nb_epoch=nb_epoch / 5,\n",
    "                        validation_data=validation_generator,\n",
    "                        nb_val_samples=nb_validation_samples,\n",
    "                        callbacks=callbacks_list)\n",
    "\n",
    "    # add the best weights from the train top model\n",
    "    # at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n",
    "    # we re-load model weights to ensure the best epoch is selected and not the last one.\n",
    "    model.load_weights(top_weights_path)\n",
    "\n",
    "    # verbose\n",
    "    print(\"\\nStarting to Fine Tune Model\\n\")\n",
    "\n",
    "    # based_model_last_block_layer_number points to the layer in your model you want to train.\n",
    "    # For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n",
    "    # If you want to train the last TWO blocks of an Inception model it should be 172\n",
    "    # layers before this number will used the pre-trained weights, layers above and including this number\n",
    "    # will be re-trained based on the new data.\n",
    "    for layer in model.layers[:based_model_last_block_layer_number]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[based_model_last_block_layer_number:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=SGD(lr=learn_rate, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
    "    final_weights_path = 'model/model_weights.h5'\n",
    "    checkpoint = ModelCheckpoint(final_weights_path, monitor='val_loss', verbose=1, save_best_only=True, mode='mode')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # fine-tune the model\n",
    "    history_ft = model.fit_generator(train_generator,\n",
    "                        samples_per_epoch=nb_train_samples,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=validation_generator,\n",
    "                        nb_val_samples=nb_validation_samples,\n",
    "                        callbacks=callbacks_list)\n",
    "    \n",
    "    # save model\n",
    "    model_json = model.to_json()\n",
    "    with open('model/model.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "    return history_tl, history_ft, model.layers\n",
    "\n",
    "\n",
    "hist_tl, hist_ft, model_layers = train(train_dir, validation_dir)  # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-6cee9294cec3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-6cee9294cec3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for i, layer in enumerate(model_layers):  # comment these two lines once the correct based_model_last_block_layer\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze: this is used to define based_model_last_block_layer_number\n",
    "    for i, layer in enumerate(model_layers):  # comment these two lines once the correct based_model_last_block_layer\n",
    "        print(i, layer.name)  # has been selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training2(history):\n",
    "    #% matplotlib inline\n",
    "\n",
    "    df = pd.DataFrame(history.history)\n",
    "    # display(df)\n",
    "\n",
    "    plot = df.plot(y=['loss', 'val_loss'], figsize=(8, 4), title='Training and validation loss', legend=True)\n",
    "    plot.set_xlabel('Epochs')\n",
    "    plot.set_ylabel('Loss binary_crossentropy')    \n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('loss_graph_t_cancer_t:'+str(nb_train_samples)+'smp_v:'+str(nb_validation_samples)+'smp_'+str(nb_epoch)+'epc.png')\n",
    "\n",
    "    plot = df.plot(y=['acc', 'val_acc'], figsize=(8, 4), title='Training and validation accuracy', legend=True)\n",
    "    plot.set_xlabel('Epochs')\n",
    "    plot.set_ylabel('Accuracy')\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('acc_graph_t_cancer_t:'+str(nb_train_samples)+'smp_v:'+str(nb_validation_samples)+'smp_'+str(nb_epoch)+'epc.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_training2(hist_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training2(hist_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release memory\n",
    "k.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
